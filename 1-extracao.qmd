---
title: "Script de extração dos *skeets* via API com a biblioteca `{atrrr}`"
format: 
  html:
    toc: true
    toc-depth: 5
    toc-location: left
    embed-resources: true
execute: 
  cache: true
---

```{r}
#| label: setup

library(atrrr)
library(tidyverse)

# funções utilitárias
dia.da.semana <- function(w.day) {
  case_match(
    w.day,
    1 ~ "domingo",
    7 ~ "sábado",
    .default = 
      case_match(
        w.day, 
        2 ~ "segunda",
        3 ~ "terça",
        4 ~ "quarta",
        5 ~ "quinta",
        6 ~ "sexta",
      ) |> 
      str_c("-feira"),
  )
}

`%!in%` <- negate(`%in%`)
```

## Definindo os parâmetros da busca

### De quando a quando buscar? 

Quando o Twitter foi bloqueado por Big Xande?

```{r}
#| label: def-inicio-bloqueio

inicio.bloqueio <- "30-08-2024" |> dmy()
inicio.busca <- inicio.bloqueio - 4 * dweeks()
```

Começou em uma `r inicio.bloqueio |> wday() |> dia.da.semana()`, que é quando precisa ser o início dos blocos de 7 dias.

Nota: nesse caso, um bloco de 7 dias é diferente de uma semana, pois o bloco não começa necessariamente em um domingo.

Vamos buscar mais quatro blocos de 7 dias antes para estabelecer um baseline de atividade no Bluesky anterior ao bloqueio do Twitter

```{r}
#| label: def-inicio-busca
#| dependson: def-inicio-bloqueio

(inicio.busca <- inicio.bloqueio - 4 * dweeks())
```

Quando Big Xande liberou de volta o twitter?

```{r}
#| label: def-final-bloqueio

final.bloqueio <- "08-10-2024" |> dmy()
```

Foi numa `r final.bloqueio |> wday() |> dia.da.semana()`.

O bloqueio durou `r (n.dias.bloqueio <- (final.bloqueio - inicio.bloqueio + 1) |> as.numeric())` dias, então não vai ser um número redondo de blocos de 7 dias, mas sim `r n.dias.bloqueio / 7` blocos de 7 dias, ou seja `r n.dias.bloqueio %/% 7` blocos mais `r n.dias.bloqueio %% 7` dias e caiu o desbloqueio no `r n.dias.bloqueio %% 7`^o^ dia do `r n.dias.bloqueio %/% 7 + 1`^o^ bloco.

```{r}
#| label: def-final-busca
#| dependson: def-final-bloqueio

(final.busca <- final.bloqueio + 2 * ddays() + 4 * dweeks())
```

Isso dá `r final.busca - inicio.busca + 1` dias ou `r (final.busca - inicio.busca + 1) / 7` blocos de 7 dias, dos quais:

- blocos 1 a 4: 1 mês antes
- bloco 5: bloqueia 1o dia desse bloco
- blocos 6 a 9: só bluesky
- bloco 10: desbloqueia no 5o dia desse bloco
- blocos 11 a 14: X voltando a funcionar e bluesky esvaziando

### Por qual termos buscar?

Em princípio, poderia ser `'cblol'` ou `'"#cblol"'` ou mais algum outro termos de busca, mas vou ficar só com `'cblol'` mesmo.

## Autenticando

```{r}
#| label: autenticando

auth(
  user = 'yasmelinss.bsky.social',
  password = read_lines("senha.txt"),
  overwrite = TRUE
)
```

## Buscando skeets 

### Primeira tentativa: tudo de uma vez 

```{r}
(
  skeets.cblol <-
  search_post(
    q = "cblol",
    since = inicio.busca,
    until = final.busca
  )
) |> 
  nrow()
```

Ué, só 184 skeets?!?

```{r}
(
  skeets.hash.cblol <-
  search_post(
    q = '"#cblol"',
    since = inicio.busca,
    until = final.busca
  )
) |> 
  nrow()
```

Aqui deu 184 skeets também.

```{r}
skeets.cblol$uri |> length()
skeets.hash.cblol$uri |> length()
```

O mesmo resultado em ambos quando busca com `"cblol"` ou com `'"#cblol"'`.

```{r}
intersect(
  skeets.cblol$uri,
  skeets.hash.cblol$uri
) |> length()
```

Pelo menos, as duas buscas dão o mesmo retorno.

Não parece confiável tentar extrair tudo de uma vez.

### Deu merda sim. Porquê?

No manual do `{atrrr}` aparece o motivo: o próprio protocolo tem uma limitação de 100 buscas no máximo.

Assim, só dá para confiar em buscas que retornaram menos de 100 *skeets*.

### Segunda tentativa: fatiando

Criando uma função para lidar com possíveis erros no retorno da API

```{r}
#| label: def-my.search.posts

my.search.post <- 
  insistently(
    f = search_post,
    quiet = FALSE,
    rate = rate_backoff(max_times = 5)
  )
```

#### Fatiando por dia 

A busca vai ser feita individualmente nestes dias e vamos ver quantos skeets são retornados em cada dia.

```{r}
#| label: puxa-skeets-dia
#| dependson: def-my.search.posts

(dias.buscas <- seq(inicio.busca, final.busca))
skeets.cblol.por.dia <-
  seq(inicio.busca, final.busca) |>
  map(
    \(inicio.bloco) {
      list(
        inicio = inicio.bloco,
        final = inicio.bloco + 1 * ddays(),
        skeets =
          my.search.post(
            q = "cblol",
            since = inicio.bloco,
            until = inicio.bloco + 1 * ddays()
          )
      )
    }
  )
```

##### Resultados

Tem muitos dia que retornaram mais do que 100 skeets?

```{r}
#| label: def-dias-a-refinar
#| dependson: puxa-skeets-dia

(
  n.skeets.por.dia <-
  skeets.cblol.por.dia |>
  map_dfr(
    function(bloco)
      tibble(
        dia = bloco$inicio,
        n.skeets = nrow(bloco$skeets)
      )
  )
)
(
  dias.a.refinar <-
    n.skeets.por.dia |>
    filter(n.skeets >= 100) |>
    pull(dia)
)
```

É gente pra caramba: `r 100*length(dias.a.refinar)/length(dias.buscas)`% dos dias precisam ser refinados.

O jeito vai ser refinar a busca nos dias em que deu xabu, particionando cada dia em dois.

Mas antes, vou montar o dataframe com os dias que retornaram direito.

```{r}
#| label: salva-skeets.dias.ok
#| dependson: def-dias-a-refinar

(
  skeets.dias.ok <-
  skeets.cblol.por.dia[dias.buscas %!in% dias.a.refinar] |>
  map(\(x) x$skeets) |>
  list_rbind()
)
```

#### Refinando os dias com excesso de postagem

Quebrando cada dia em dois blocos de 12h.

```{r}
#| label: puxa-skeets-12h
#| dependson: def-my.search.posts, def-dias-a-refinar

(
  blocos.12h.buscas <-
    expand_grid(
      dia = dias.a.refinar,
      hora = 0:1 * 12 * dhours()
    ) |>
    mutate(quando = dia + hora) |>
    pull(quando)
)

skeets.cblol.por.12h <-
  blocos.12h.buscas |>
  map(
    \(inicio.bloco) {
      list(
        inicio = inicio.bloco,
        final = inicio.bloco + 12 * dhours(),
        skeets =
          my.search.post(
            q = "cblol",
            since = inicio.bloco,
            until = inicio.bloco + 12 * dhours()
          )
      )
    }
  )
```

##### Resultados

Ainda precisa refinar?

```{r}
#| label: def-12h-a-refinar
#| dependson: puxa-skeet-12h

(
  n.skeets.por.12h <-
  skeets.cblol.por.12h |>
  map_dfr(
    function(bloco)
      tibble(
        quando = bloco$inicio,
        n.skeets = nrow(bloco$skeets)
      )
  )
)

blocos.12h.a.refinar <-
  n.skeets.por.12h |>
  filter(n.skeets >= 100) |>
  pull(quando)
```

Salvando os skeets de dias sem excesso de skeets.

```{r}
#| label: salva-skeets.12h.ok
#| dependson: puxa-skeets-12h

(
skeets.12h.ok <-
  skeets.cblol.por.12h[blocos.12h.buscas %!in% blocos.12h.a.refinar] |>
  map(\(x) x$skeets) |>
  list_rbind()
)
```

#### Refinando os blocos de 12h com excesso de postagem

```{r}
#| label: puxa-skeets-6h
#| dependson: def-my.search.posts, def-12h-a-refinar

(
  blocos.6h.buscas <-
    expand_grid(
      dia = blocos.12h.a.refinar,
      hora = 0:1 * 6 * dhours()
    ) |>
    mutate(quando = dia + hora) |>
    pull(quando)
)

skeets.cblol.por.6h <-
  blocos.6h.buscas |>
  map(
    \(inicio.bloco) {
      list(
        inicio = inicio.bloco,
        final = inicio.bloco + 6 * dhours(),
        skeets =
          my.search.post(
            q = "cblol",
            since = inicio.bloco,
            until = inicio.bloco + 6 * dhours()
          )
      )
    }
  )
```

##### Resultados

```{r}
#| label: def-6h-a-refinar
#| dependson: puxa-skeets-6h
(
  n.skeets.por.6h <-
  skeets.cblol.por.6h |>
  map_dfr(
    function(bloco)
      tibble(
        quando = bloco$inicio,
        n.skeets = nrow(bloco$skeets)
      )
  )
)

(
  blocos.6h.a.refinar <-
  n.skeets.por.6h |>
  filter(n.skeets >= 100) |>
  pull(quando)
)
```

```{r}
#| label: salva-skeets.6h.ok
#| dependson: puxa-skeets-6h

(
  skeets.6h.ok <-
  skeets.cblol.por.6h[blocos.6h.buscas %!in% blocos.6h.a.refinar] |>
  map(\(x) x$skeets) |>
  list_rbind()
)
```

#### Refinando os blocos de 6h com excesso de postagem 

```{r}
#| label: puxa-skeets-3h
#| dependson: def-my.search.posts, def-6h-a-refinar

(
  blocos.3h.buscas <-
    expand_grid(
      dia = blocos.6h.a.refinar,
      hora = 0:1 * 3 * dhours()
    ) |>
    mutate(quando = dia + hora) |>
    pull(quando)
)

skeets.cblol.por.3h <-
  blocos.3h.buscas |>
  map(
    \(inicio.bloco) {
      list(
        inicio = inicio.bloco,
        final = inicio.bloco + 3 * dhours(),
        skeets =
          my.search.post(
            q = "cblol",
            since = inicio.bloco,
            until = inicio.bloco + 3 * dhours()
          )
      )
    }
  )
```

##### Resultados

```{r}
#| label: def-3h-a-refinar
#| dependson: puxa-skeets-3h

(
  n.skeets.por.3h <-
    skeets.cblol.por.3h |>
    map_dfr(
      function(bloco)
        tibble(
          quando = bloco$inicio,
          n.skeets = nrow(bloco$skeets)
        )
    )
)

(
  blocos.3h.a.refinar <-
    n.skeets.por.3h |>
    filter(n.skeets >= 100) |>
    pull(quando)
)
```

```{r}
#| label: salva-skeets.3h.ok
#| dependson: puxa-skeets-3h

(
  skeets.3h.ok <-
    skeets.cblol.por.3h[blocos.3h.buscas %!in% blocos.3h.a.refinar] |>
    map(\(x) x$skeets) |>
    list_rbind()
)
```

#### Refinando os blocos de 3h com excesso de postagem 

```{r}
#| label: puxa-skeets-1h
#| dependson: def-my.search.posts, def-3h-a-refinar

(
  blocos.1h.buscas <-
    expand_grid(
      dia = blocos.3h.a.refinar,
      hora = 0:2 * dhours()
    ) |>
    mutate(quando = dia + hora) |>
    pull(quando)
)

skeets.cblol.por.1h <-
  blocos.1h.buscas |>
  map(
    \(inicio.bloco) {
      list(
        inicio = inicio.bloco,
        final = inicio.bloco + 1 * dhours(),
        skeets =
          my.search.post(
            q = "cblol",
            since = inicio.bloco,
            until = inicio.bloco + 1 * dhours()
          )
      )
    }
  )
```

##### Resultados

```{r}
#| label: def-1h-a-refinar
#| dependson: puxa-skeets-1h

n.skeets.por.1h <-
  skeets.cblol.por.1h |>
  map_dfr(
    function(bloco)
      tibble(
        quando = bloco$inicio,
        n.skeets = nrow(bloco$skeets)
      )
  )

blocos.1h.a.refinar <-
  n.skeets.por.1h |>
  filter(n.skeets >= 100) |>
  pull(quando)
```

```{r}
#| label: salva-skeets.1h.ok
#| dependson: puxa-skeets-1h

(
  skeets.1h.ok <-
    skeets.cblol.por.1h[blocos.1h.buscas %!in% blocos.1h.a.refinar] |>
    map(\(x) x$skeets) |>
    list_rbind()
)
```

#### Refinando os blocos de 1h com excesso de postagem 

```{r}
#| label: puxa-skeets-30min
#| dependson: def-my.search.posts, def-1h-a-refinar

(
  blocos.30min.buscas <-
    expand_grid(
      dia = blocos.1h.a.refinar,
      hora = 0:1 * 30 * dminutes()
    ) |>
    mutate(quando = dia + hora) |>
    pull(quando)
)

skeets.cblol.por.30min <-
  blocos.30min.buscas |>
  map(
    \(inicio.bloco) {
      list(
        inicio = inicio.bloco,
        final = inicio.bloco + 30 * dminutes(),
        skeets =
          my.search.post(
            q = "cblol",
            since = inicio.bloco,
            until = inicio.bloco + 30 * dminutes()
          )
      )
    }
  )
```

##### Resultados

```{r}
#| label: def-30min-a-refinar
#| dependson: puxa-skeets-30min

(
  n.skeets.por.30min <-
    skeets.cblol.por.30min |>
    map_dfr(
      function(bloco)
        tibble(
          quando = bloco$inicio,
          n.skeets = nrow(bloco$skeets)
        )
    )
)

(
  blocos.30min.a.refinar <-
    n.skeets.por.30min |>
    filter(n.skeets >= 100) |>
    pull(quando)
)
```

```{r}
#| label: salva-skeets.30min.ok
#| dependson: puxa-skeets-30min

(
  skeets.30min.ok <-
    skeets.cblol.por.30min[blocos.30min.buscas %!in% blocos.30min.a.refinar] |>
    map(\(x) x$skeets) |>
    list_rbind()
)
```

#### Refinando os blocos de 30min com excesso de postagem 

```{r}
#| label: puxa-skeets-10min
#| dependson: def-my.search.posts, def-30min-a-refinar

(
  blocos.10min.buscas <-
    expand_grid(
      dia = blocos.30min.a.refinar,
      hora = 0:2 * 10 * dminutes()
    ) |>
    mutate(quando = dia + hora) |>
    pull(quando)
)

skeets.cblol.por.10min <-
  blocos.10min.buscas |>
  map(
    \(inicio.bloco) {
      list(
        inicio = inicio.bloco,
        final = inicio.bloco + 10 * dminutes(),
        skeets =
          my.search.post(
            q = "cblol",
            since = inicio.bloco,
            until = inicio.bloco + 10 * dminutes()
          )
      )
    }
  )
```

##### Resultados

```{r}
#| label: def-10min-a-refinar
#| dependson: puxa-skeets-10min

(
  n.skeets.por.10min <-
    skeets.cblol.por.10min |>
    map_dfr(
      function(bloco)
        tibble(
          quando = bloco$inicio,
          n.skeets = nrow(bloco$skeets)
        )
    )
)

(
  blocos.10min.a.refinar <-
    n.skeets.por.10min |>
    filter(n.skeets >= 100) |>
    pull(quando)
)
```

```{r}
#| label: salva-skeets.10min.ok 
#| dependson: puxa-skeets-10min

(
  skeets.10min.ok <-
    skeets.cblol.por.10min[blocos.10min.buscas %!in% blocos.10min.a.refinar] |>
    map(\(x) x$skeets) |>
    list_rbind()
)
```

#### Refinando os blocos de 10min com excesso de postagem 

```{r}
#| label: puxa-skeets-5min
#| dependson: def-my.search.posts, def-10min-a-refinar

(
  blocos.5min.buscas <-
    expand_grid(
      dia = blocos.10min.a.refinar,
      hora = 0:2 * 5 * dminutes()
    ) |>
    mutate(quando = dia + hora) |>
    pull(quando)
)

skeets.cblol.por.5min <-
  blocos.5min.buscas |>
  map(
    \(inicio.bloco) {
      list(
        inicio = inicio.bloco,
        final = inicio.bloco + 5 * dminutes(),
        skeets =
          my.search.post(
            q = "cblol",
            since = inicio.bloco,
            until = inicio.bloco + 5 * dminutes()
          )
      )
    }
  )
```

##### Resultados

```{r}
#| label: def-5min-a-refinar
#| dependson: puxa-skeets-5min

(
  n.skeets.por.5min <-
    skeets.cblol.por.5min |>
    map_dfr(
      function(bloco)
        tibble(
          quando = bloco$inicio,
          n.skeets = nrow(bloco$skeets)
        )
    )
)

(
  blocos.5min.a.refinar <-
    n.skeets.por.5min |>
    filter(n.skeets >= 100) |>
    pull(quando)
)
```

```{r}
#| label: salva-skeets.5min.ok 
#| dependson: puxa-skeets-5min

(
  skeets.5min.ok <-
    skeets.cblol.por.5min[blocos.5min.buscas %!in% blocos.5min.a.refinar] |>
    map(\(x) x$skeets) |>
    list_rbind()
)
```

#### Refinando os blocos de 5min com excesso de postagem 

```{r}
#| label: puxa-skeets-1min
#| dependson: def-my.search.posts, def-5min-a-refinar

(
  blocos.1min.buscas <-
    expand_grid(
      dia = blocos.5min.a.refinar,
      hora = 0:4 * 1 * dminutes()
    ) |>
    mutate(quando = dia + hora) |>
    pull(quando)
)

skeets.cblol.por.1min <-
  blocos.1min.buscas |>
  map(
    \(inicio.bloco) {
      list(
        inicio = inicio.bloco,
        final = inicio.bloco + 1 * dminutes(),
        skeets =
          my.search.post(
            q = "cblol",
            since = inicio.bloco,
            until = inicio.bloco + 1 * dminutes()
          )
      )
    }
  )
```

##### Resultados

```{r}
#| label: def-1min-a-refinar
#| dependson: puxa-skeets-1min

(
  n.skeets.por.1min <-
    skeets.cblol.por.1min |>
    map_dfr(
      function(bloco)
        tibble(
          quando = bloco$inicio,
          n.skeets = nrow(bloco$skeets)
        )
    )
)

(
  blocos.1min.a.refinar <-
    n.skeets.por.1min |>
    filter(n.skeets >= 100) |>
    pull(quando)
) |> 
  length()
```

Finalmente não precisou mais refinar!

```{r}
#| label: salva-skeets.1min.ok 
#| dependson: puxa-skeets-1min

(
  skeets.1min.ok <-
    skeets.cblol.por.1min |>
    map(\(x) x$skeets) |>
    list_rbind()
)
```

#### Juntando os blocos de skeets

```{r}
#| label: junta-skeets
#| dependson: salva-skeets.dia.ok, salva-skeets.12h.ok, salva-skeets.6h.ok, salva-skeets.3h.ok, salva-skeets.1h.ok, salva-skeets.30min.ok, salva-skeets.10min.ok, salva-skeets.5min.ok, salva-skeets.1min.ok

(
  skeets <-
    bind_rows(
      skeets.dias.ok,
      skeets.12h.ok,
      skeets.6h.ok,
      skeets.3h.ok,
      skeets.1h.ok,
      skeets.30min.ok,
      skeets.10min.ok,
      skeets.5min.ok,
      skeets.1min.ok,
      .id = "bloco"
    )
) |> 
  nrow()

# Por ora, não está precisando rodar isto pra liberar espaço
# rm(
#   skeets.dias.ok,
#   skeets.12h.ok,
#   skeets.6h.ok,
#   skeets.3h.ok,
#   skeets.1h.ok,
#   skeets.30min.ok,
#   skeets.10min.ok,
#   skeets.5min.ok,
#   skeets.1min.ok
# )
```

Há repetecos?

```{r}
#| label: checa-skeets-duplicados
#| dependson: junta-skeets

any(duplicated(skeets$uri))
skeets |> 
  mutate(
    duplicatas = duplicated(uri) | duplicated(uri, fromLast = TRUE),
    linha = row_number()
  ) |> 
  filter(duplicatas) |> 
  select(bloco, linha, uri) |> 
  arrange(uri, bloco, linha) # |> View()
```

Sim, há.

Eliminando as redundâncias:

```{r}
#| label: elimina-skeets-duplicados
#| dependson: junta-skeets

(
  skeets <- 
    skeets |> 
    filter(!duplicated(uri))
) |> 
  nrow()
```

Separando os dados mais úteis

```{r}
#| label: separa-did-data-uri-to
#| dependson: elimina-skeets-duplicados

autores <- 
  skeets$author_data |>
  map_chr(\(x) x$did)
quando <- 
  skeets$post_data |>
  map_chr(\(x) x$createdAt)
uri <- 
  skeets$uri
to <- 
  skeets$in_reply_to
```

### Salvando os skeets baixados

```{r}
#| label: salva-skeets
#| dependson: elimina-duplicatas

write_rds(skeets, "Dados/skeets-cblol.rds")
save(autores, quando, uri, to, file = "Dados/curtos.rda")

### pro caso de precisar carregar rápido:
# skeets <- read_rds("Dados/skeets-cblol.rds")
# load(file = "Dados/curtos.rda")

### por ora, não está precisando rodar isto pra economizar espaço
# rm(skeets)
```

## Ainda precisa baixar dados para consefguir calcular KPIs?

Replies e quotes são interações com um skeets inicial ou com outro reply ou outro quote, então têm que ser contabilizados para calcular métricas de conectividade, de centralidade e outras

Isso cabe aqui ou seria na faxina de dados ou na análise dos dados?

De qualquer forma, tem que ver se precisa puxar mais algum dado do Bluesky ou se só depende dos dados já baixados

[TO-DO!!! O quê mais que eu tinha que fazer aqui mesmo?]{.mark}

## Buscando threads desses skeets (inclui replies e reskeets) 

[TO-DO!!!]{.mark}

```{r}
#| label: puxa-threads
#| dependson: separa-did-data-uri-to

# falta fazer
```

## Juntando todos os skeets 

[TO-DO!!!]{.mark}

```{r}
#| label: junta-skeets-threads
#| dependson: elimina-skeets-duplicados, puxa-threads

# falta fazer
```

## Buscando users que deram like em todos esses skeets 

Definindo a função de busca de perfis que deram *like* que faz tratamento de erros de busca

```{r}
#| label: def-my.get.likes

my.get.likes <- 
  insistently(
    f = get_likes, 
    quiet = FALSE,
    rate = rate_backoff(max_times = 5)
  )
```

Puxando os *likes* dos skeets coletados

```{r}
#| label: puxa-likes
#| dependson: def-my.get.likes, separa-did-data-uri-to, junta-skeets-threads

usuarios.likes <- 
  uri |> 
  map_dfr(
    \(uri) {
      print(uri)
      limite <- 1000
      tentativa <- my.get.likes(uri, limit = limite)
      while (nrow(tentativa) > limite) {
        limite <- limite * 2
        Sys.sleep(1)
        tentativa <- my.get.likes(uri, limit = limite)
      }
    }
  )

# para uso temporário
write_rds(usuarios.likes, file = "Dados/usuarios-likes.rds")
# usuarios.likes <- read_rds("Dados/usuarios-likes.rds")
```

## Buscando users que deram reposts em todos esses skeets 

```{r}
#| label: def-my.get.reposts

my.get.reposts <- 
  insistently(
    f = get_reposts, 
    quiet = FALSE,
    rate = rate_backoff(max_times = 5)
  )
```

```{r}
#| label: puxa-reposts
#| dependson: junta-skeets-threads, def-my.get.reposts, puxa-likes

usuarios.reposts <- 
  uri |> 
  map_dfr(
    \(uri) {
      print(uri)
      limite <- 1000
      tentativa <- my.get.reposts(uri, limit = limite)
      while (nrow(tentativa) > limite) {
        limite <- limite * 2
        Sys.sleep(1)
        tentativa <- my.get.reposts(uri, limit = limite)
      }
    }
  )

# para uso temporário
write_rds(usuarios.reposts, file = "Dados/usuarios-reposts.rds")
# usuarios.reposts <- read_rds("Dados/usuarios-reposts.rds")
```

## Juntando todos os users, vindos de posts, de likes ou reposts

[TO-DO!!!]{.mark}

```{r}
#| label: junta-users
#| dependson: junta-skeets-threads, puxa-likes, puxa-reposts

# falta fazer
```

## Salvando Tudo!!!

[TO-DO!!!]{.mark}

```{r}
#| eval: false
search_post()
search_feed()
get_feed()
get_replies()
get_reposts()
get_thread()
get_likes()
get_user_info()
get_actor_likes()
get_actor_starter_packs()
#| label: salva-posts-users
#| dependson: junta-skeets-threads, junta-users

# Falta fazer
```
## Lembrar de verificar se usou, se precisa usar ou se não precisa
