---
title: "Script de extração dos *skeets* via API com a biblioteca `{atrrr}`"
format: 
  html:
    toc: true
    toc-depth: 5
    toc-location: left
    embed-resources: true
execute: 
  cache: true
---

```{r}
#| label: setup

library(atrrr)
library(dplyr)
library(lubridate)
library(purrr)
library(tidyverse)
library(tictoc)

# funções utilitárias

dia.da.semana <- function(w.day) {
  case_match(
    w.day,
    1 ~ "domingo",
    7 ~ "sábado",
    .default = 
      case_match(
        w.day, 
        2 ~ "segunda",
        3 ~ "terça",
        4 ~ "quarta",
        5 ~ "quinta",
        6 ~ "sexta",
      ) |> 
      str_c("-feira"),
  )
}

`%!in%` <- negate(`%in%`)

# para rastrear enquanto renderiza
out <- "Dados/dump.txt"
cat("", file = out)  # zera o arquivo
dump.cat <- function(...) cat(..., "\n", file = out, append = TRUE)
dump.print <- function(nome, objeto) dump.cat(nome, "=", objeto)

```

## Definindo os parâmetros da busca

### De quando a quando buscar? 

Quando o Twitter foi bloqueado por Big Xande?

```{r}
#| label: def-inicio-bloqueio

inicio.bloqueio <- "30-08-2024" |> dmy()
```

Começou em uma `r inicio.bloqueio |> wday() |> dia.da.semana()`, que é quando precisa ser o início dos blocos de 7 dias.

Nota: nesse caso, um bloco de 7 dias é diferente de uma semana, pois o bloco não começa necessariamente em um domingo.

Vamos buscar mais quatro blocos de 7 dias antes para estabelecer um baseline de atividade no Bluesky anterior ao bloqueio do Twitter

```{r}
#| label: def-inicio-busca
#| dependson: def-inicio-bloqueio

(inicio.busca <- inicio.bloqueio - 4 * dweeks())
```

Quando Big Xande liberou de volta o twitter?

```{r}
#| label: def-final-bloqueio

final.bloqueio <- "08-10-2024" |> dmy()
```

Foi numa `r final.bloqueio |> wday() |> dia.da.semana()`.

O bloqueio durou `r (n.dias.bloqueio <- (final.bloqueio - inicio.bloqueio + 1) |> as.numeric())` dias, então não vai ser um número redondo de blocos de 7 dias, mas sim `r n.dias.bloqueio / 7` blocos de 7 dias, ou seja `r n.dias.bloqueio %/% 7` blocos mais `r n.dias.bloqueio %% 7` dias e caiu o desbloqueio no `r n.dias.bloqueio %% 7`^o^ dia do `r n.dias.bloqueio %/% 7 + 1`^o^ bloco.

```{r}
#| label: def-final-busca
#| dependson: def-final-bloqueio

(final.busca <- final.bloqueio + 2 * ddays() + 4 * dweeks())
```

Isso dá `r final.busca - inicio.busca + 1` dias ou `r (final.busca - inicio.busca + 1) / 7` blocos de 7 dias, dos quais:

- blocos 1 a 4: 1 mês antes
- bloco 5: bloqueia 1o dia desse bloco
- blocos 6 a 9: só bluesky
- bloco 10: desbloqueia no 5o dia desse bloco
- blocos 11 a 14: X voltando a funcionar e bluesky esvaziando

### Por qual termos buscar?

Em princípio, poderia ser `'cblol'` ou `'"#cblol"'` ou mais algum outro termos de busca, mas vou ficar só com `'cblol'` mesmo.

## Autenticando

```{r}
#| label: autenticando

auth(
  user = 'yasmelinss.bsky.social',
  password = read_lines("senha.txt"),
  overwrite = TRUE
)
```

## Buscando skeets por dia

A busca vai ser feita individualmente por dias e com limite maior do que 100 skeets.

```{r}
#| label: puxa-skeets-dia
#| dependson: def-inicio-busca, def-final.busca
#| collapse: true

(dias.buscas <- seq(inicio.busca, final.busca))

my.search.post <- 
  insistently(
    f = search_post,
    quiet = FALSE,
    rate = rate_backoff(max_times = 5)
  )

dump.cat("=======================")
dump.cat("buscando skeets por dia")

skeets.por.dia <- 
  seq(inicio.busca, final.busca) |>
  map(
    \(dia) {
      skeets <- 
        my.search.post(
          q = "cblol",
          since = dia,
          until = dia + 1 * ddays(),
          limit = 6000
        )
      dump.cat("dia =", dia, "; n.skeets =", nrow(skeets))
      list(
        dia = dia,
        skeets = skeets
      )
    }
  )
```

Algum dia retornou mais do que 6000 skeets?

```{r}
#| label: checa-limite-skeets
#| dependson: puxa-skeets-dia

skeets.por.dia |> 
  map_int(\(x) x$skeets |> nrow()) > 6000
```

Juntando tudo em um único dataframe

```{r}
#| label: juntando-skeets-dia
#| dependson: puxa-skeets-dia

skeets <- 
  skeets.por.dia |> 
  map(\(x) x$skeets) |> 
  list_rbind()

nrow(skeets)
```

Há repetecos?

```{r}
#| label: checa-skeets-duplicados
#| dependson: puxa-skeets-dia

any(duplicated(skeets$uri))
```

Separando os dados mais úteis

```{r}
#| label: separa-skeets-curto
#| dependson: puxa-skeets-dia

skeets.curto <- 
  skeets |> 
  mutate(
    did.autor = 
      author_data |>
      map_chr(\(x) x$did),
    data.post = 
      post_data |>
      map_chr(\(x) x$createdAt),
    uri.post = uri,
    uri.reply = in_reply_to,
    .keep = "none"
  )
```

Salvando os skeets baixados

```{r}
#| label: salva-skeets
#| dependson: puxa-skeets-dia, separa-skeets-curto

write_rds(skeets, "Dados/skeets-cblol.rds")
write_rds(skeets.curto, "Dados/skeets-curto.rds")

### pro caso de precisar carregar rápido:
# skeets <- read_rds("Dados/skeets.rds")
# skeets.curto <- read_rds("Dados/skeets-curto.rds")

### por ora, não está precisando rodar isto pra economizar espaço
# rm(skeets)
```

## Ainda precisa baixar dados para conseguir calcular KPIs?

Replies e quotes são interações com um skeets inicial ou com outro reply ou outro quote, então têm que ser contabilizados para calcular métricas de conectividade, de centralidade e outras

Isso cabe aqui ou seria na faxina de dados ou na análise dos dados?

De qualquer forma, tem que ver se precisa puxar mais algum dado do Bluesky ou se só depende dos dados já baixados

[TO-DO!!! O quê mais que eu tinha que fazer aqui mesmo?]{.mark}

## Buscando threads desses skeets (inclui replies e reskeets) 

[TO-DO!!!]{.mark}

```{r}
#| label: puxa-threads
#| dependson: separa-skeets-curto

# falta fazer
```

## Juntando todos os skeets 

[TO-DO!!!]{.mark}

```{r}
#| label: junta-skeets-threads
#| dependson: elimina-skeets-duplicados, puxa-threads

# falta fazer
```

## Buscando users que deram like em todos esses skeets 

Definindo a função de busca de perfis que deram *like* que faz tratamento de erros de busca

[AQUI!!!]{.mark}

```{r}
#| label: def-my.get.likes

my.get.likes <- 
  insistently(
    f = get_likes, 
    quiet = FALSE,
    rate = rate_backoff(pause_min = 0.1, max_times = 5)
  )
```

Verificando quais likes já foram baixados e eliminando da busca

```{r}
#| label: corta-likes-ja-baixados
#| dependson: separa-skeets-curto, junta-skeets-threads

(
  likes.baixados <- 
    list.files(
      path = "Dados/likes", 
      pattern = "*.rds"
    ) |> 
    str_remove("\\..*$") |> 
    str_replace("^", "at://did:plc:") |> 
    str_replace("-", "/app.bsky.feed.post/")
) |> 
  length()

(
  likes.a.baixar <- 
    skeets.curto$uri.post |> 
    setdiff(likes.baixados)
) |> 
  length()
```

Puxando os *likes* dos skeets coletados

```{r}
#| label: puxa-likes
#| dependson: def-my.get.likes, corta-likes-ja-baixados

dump.cat("============================")
dump.cat("buscando likes")

likes <- 
  walk2(
    likes.a.baixar,
    seq_along(likes.a.baixar),
    function(uri, i, n) {
      dump.cat("---------")
      dump.cat("i =", i, "/", n, "; uri =", uri, "; hora =", Sys.time())
      # limite <- 6000
      tic()
      like <- my.get.likes(uri, limit = Inf)
      dump.cat("limite =", limite, "; puxou =", nrow(like))
      # while (nrow(like) > limite) {
      #   limite <- limite * 2
      #   like <- my.get.likes(uri, limit = limite)
      #   dump.cat("limite =", limite, "; puxou =", nrow(like))
      # }
      tempo <- toc()
      nome <- 
        uri |> 
        str_remove("at://did:plc:") |> 
        str_replace("/app.bsky.feed.post/", "-")
      dump.cat(
        "puxou =", nrow(like),
        "; tempo =", tempo[[2]] - tempo[[1]],
        "; file =", nome
      )
      write_rds(
        like, 
        file = str_c("Dados/likes/", nome, ".rds")
      )
    },
    n = length(likes.a.baixar)
  )
```

## Buscando users que deram reposts em todos esses skeets 

[AQUI!!!]{.mark}

```{r}
#| label: def-my.get.reposts

my.get.reposts <- 
  insistently(
    f = get_reposts, 
    quiet = FALSE,
    rate = rate_backoff(max_times = 5)
  )
```

```{r}
#| label: puxa-reposts
#| dependson: junta-skeets-threads, def-my.get.reposts, puxa-likes

reposts <- 
  skeets$uri |> 
  map_dfr(
    \(uri) {
      print(uri)
      limite <- 6000
      tentativa <- my.get.reposts(uri, limit = limite)
      while (nrow(tentativa) > limite) {
        limite <- limite * 2
        tentativa <- my.get.reposts(uri, limit = limite)
      }
    }
  )

# para uso temporário
write_rds(usuarios.reposts, file = "Dados/usuarios-reposts.rds")
# usuarios.reposts <- read_rds("Dados/usuarios-reposts.rds")
```

## Juntando todos os users, vindos de posts, de likes ou reposts

[TO-DO!!!]{.mark}

```{r}
#| label: junta-users
#| dependson: junta-skeets-threads, puxa-likes, puxa-reposts

# falta fazer
```

## Salvando Tudo!!!

[TO-DO!!!]{.mark}

```{r}
#| label: salva-posts-users
#| dependson: junta-skeets-threads, junta-users

# Falta fazer
```

## Lembrar de verificar se usou, se precisa usar ou se não precisa

Funções de extração já usadas:

- `search_post()`
- `get_replies()`
- `get_reposts()`
- `get_likes()`

Falta usar:

- `get_follows()`
- `get_followers()`
- `get_user_info()`

Descobrir se chega a precisar usar:

- `search_feed()`
- `get_feed()`
- `get_thread()`
- `get_actor_likes()`
- `get_actor_starter_packs()`
- `get_list()`
- `get_own_timeline()`


